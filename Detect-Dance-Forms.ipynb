{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from fastai.imports import *\nimport fastai\nimport fastai.utils.collect_env\nfrom fastai.widgets import *\nfastai.utils.collect_env.show_install(1)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\n\n```text\n=== Software === \npython       : 3.7.6\nfastai       : 1.0.61\nfastprogress : 0.2.3\ntorch        : 1.5.0\ntorch cuda   : None / is **Not available** \n\n=== Hardware === \nNo GPUs available \n\n=== Environment === \nplatform     : Linux-5.4.104+-x86_64-with-debian-buster-sid\ndistro       : #1 SMP Tue Apr 6 09:49:56 PDT 2021\nconda env    : Unknown\npython       : /opt/conda/bin/python3.7\nsys.path     : /kaggle/working\n/kaggle/lib/kagglegym\n/kaggle/lib\n/opt/conda/lib/python37.zip\n/opt/conda/lib/python3.7\n/opt/conda/lib/python3.7/lib-dynload\n\n/root/.local/lib/python3.7/site-packages\n/opt/conda/lib/python3.7/site-packages\n/src/bq-helper\n/opt/conda/lib/python3.7/site-packages/IPython/extensions\n/root/.ipython\nno supported gpus found on this system\n```\n\nPlease make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.\n\nOptional package(s) to enhance the diagnostics can be installed with:\npip install distro\nOnce installed, re-run this utility to get the additional information\n","output_type":"stream"}]},{"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\n#from fastai.transforms import *\n#from fastai.conv_learner import *\n#from fastai.model import *\n#from fastai.dataset import *\n#from fastai.sgdr import *\n#from fastai.plots import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_img = '/kaggle/input/he-danceforms/dataset/train'\nfnames = get_image_files(path_img)\nfnames[:5]","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv('/kaggle/input/he-danceforms/dataset/train.csv', header='infer')\ndf1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfms = get_transforms( max_lighting=0.3, max_warp=0.2, max_zoom=1.2)\ntest_df = pd.read_csv('/kaggle/input/he-danceforms/dataset/test.csv', header='infer')\ntest_df.head()\ntest_images = ImageList.from_df(test_df, path='/kaggle/input/he-danceforms/dataset/test')\ntest_images[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = ImageDataBunch.from_df('/kaggle/input/he-danceforms/dataset/train',\\\n                              df1, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)#.add_test(test_images)\ntest = ImageList.from_df(test_df, '/kaggle/input/he-danceforms/dataset/test')\ndata.add_test(test)\ndata.show_batch(rows=3, figsize=(7,6))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data.classes)\nprint(data.c)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_datafn (imagesize,batchsize) : \n    train_img = (ImageList.from_df(df1, path='/kaggle/input/he-danceforms/dataset/train')\n        .split_by_rand_pct(0.2,seed =344) ##20% of the data is used as validation\n        .label_from_df()\n        #.add_test(test_img)\n        .transform(tfms = get_transforms(), size=imagesize)\n        .databunch(path='.',  device= torch.device('cuda:0')) #bs=batchsize,\n        .normalize(imagenet_stats)\n       )\n    test = ImageList.from_df(test_df, '/kaggle/input/he-danceforms/dataset/test')\n    train_img.add_test(test)\n    return train_img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ensemble(nmodels):\n    ens_model = [] # Empty List of ensemble model, I will store the trained learner object here \n    learning_rate =[2.95e-04,3e-04,3e-04] # List of learning rate for each model \n    model_list = [models.resnet152,models.resnet50,models.densenet201] ##List of Models . You can add resnet ones in the mix\n    for i in range(nmodels):\n        print(f'-----Training model: {i+1}--------')\n        \n        #learn.model_dir = '/kaggle/working'\n        if(i == 0 or i == 1 ):            \n            print('training for 224x224')\n            data = train_datafn(224,64)\n            learn_resnet = cnn_learner(data, model_list[i], metrics=[error_rate, accuracy,AUROC()])\n            learn_resnet.freeze_to(-1)\n            learn_resnet.fit_one_cycle(10)   # using the learning rate assigned for the first model\n            learn_resnet.lr_find()\n            learn_resnet.recorder.plot(suggestion=True)\n            learn_resnet.freeze()\n            learn_resnet.fit_one_cycle(20)\n        \n        \n            learn_resnet.save(f'ensem_model_{i}.weights')\n            ens_model.append(learn_resnet)\n            print(f'-----Training of model {i+1} complete----')\n        \n        if(i == 2):\n            data = train_datafn(64,64)\n            learn_resnet = cnn_learner(data, model_list[i], metrics=[error_rate, accuracy,AUROC()])\n            learn_resnet.freeze_to(-1)\n            print('training for 128x128')\n            learn_resnet.set_data = train_datafn(128,64) # Train the model for imagesize 128\n            learn_resnet.lr_find()\n            learn_resnet.recorder.plot(suggestion=True)\n            learn_resnet.fit_one_cycle(10,slice(learning_rate[i])) # using the learning rate for the first model \n        \n            print('training for 150x150')\n            learn_resnet.set_data = train_datafn(150,96) #Train the model for imagesize 150\n            learn_resnet.fit_one_cycle(10,slice(learning_rate[i]))   # using the learning rate assigned for the first model   \n        \n            print('training for 224x224')\n            learn_resnet.set_data = train_datafn(224,96) #Train the model for imagesize 150\n            learn_resnet.fit_one_cycle(20,slice(learning_rate[i]))   # using the learning rate assigned for the first model\n        \n        \n            learn_resnet.save(f'ensem_model_{i}.weights')\n            ens_model.append(learn_resnet)\n            print(f'-----Training of model {i+1} complete----')\n            \n             \n        \n    return ens_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install \"torch==1.4\" \"torchvision==0.5.0\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ens = get_ensemble(1)\ndata = train_datafn(224,64)\n# learn_resnet = cnn_learner(data, models.resnet50, metrics=[error_rate, accuracy,AUROC()])\n# learn_resnet.freeze_to(-1)\n# learn_resnet.fit_one_cycle(6)   # using the learning rate assigned for the first model\n# learn_resnet.save(f'ensem_model_{i}.weights')\n# ens_model.append(learn_resnet)\n# print('-----Training of model complete----')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens  = learn_resnet\nens_test_preds = [] ## Creating a list of predictions \n\npreds,_ = ens.TTA(ds_type=DatasetType.Test)\nprint(np.array(preds).shape)\nens_test_preds.append(np.array(preds))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens_preds = np.mean(ens_test_preds, axis =0)\nprint(ens_preds.shape)\nprint(ens_preds)\nlabels = np.argmax(ens_preds, 1)\ntest_df['Class'] = labels\n#['bharatanatyam', 'kathak', 'kathakali', 'kuchipudi', 'manipuri', 'mohiniyattam', 'odissi', 'sattriya']\ntest_df['Class'] = test_df['Class'].map({0: 'bharatanatyam', 1: 'kathak', 2:  'kathakali', 3:  'kuchipudi',4:'manipuri',5:'mohiniyattam',6:'odissi',7:'sattriya'})\ntest_df.to_csv('submission_ENS_2.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}